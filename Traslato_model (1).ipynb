{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Translator models"
      ],
      "metadata": {
        "id": "pUBbAn26tyES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSUzvo7srGPN",
        "outputId": "e715b59d-dea6-4703-ee3e-eb6b707a86f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "translated = model.generate(**inputs)\n",
        "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(translated_text)  # Output: Hallo, wie geht es dir?"
      ],
      "metadata": {
        "id": "Gm9xQmkVtwhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import M2M100Tokenizer, M2M100ForConditionalGeneration\n",
        "\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.src_lang = \"en\"  # Source language: English\n",
        "tokenizer.tgt_lang = \"es\"  # Target language: Spanish"
      ],
      "metadata": {
        "id": "rtv8k7Lrsx4s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"The sun is shining today.\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "translated = model.generate(**inputs, forced_bos_token_id=tokenizer.get_lang_id(\"es\"))\n",
        "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(translated_text)  # Output: El sol está brillando hoy."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR9t--tHti0K",
        "outputId": "cf48d4c6-dc19-43e3-bbc9-47db819a9050"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El sol está brillando hoy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are you up to\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "translated = model.generate(**inputs, forced_bos_token_id=tokenizer.get_lang_id(\"es\"))\n",
        "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(translated_text)  # Output: El sol está brillando hoy."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTCHGsvJtI-z",
        "outputId": "4b078c63-1687-4e92-85fa-3a663594199a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Qué estás por encima de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer.src_lang = \"fa\"  # Source: Persian\n",
        "tokenizer.tgt_lang = \"es\"  # Target language: Spanish\n",
        "\n",
        "text = \"جهان جای زیبایی برای زندگی است.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "translated = model.generate(**inputs,\n",
        "            forced_bos_token_id=tokenizer.get_lang_id(\"es\"))\n",
        "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIbhNiRathxk",
        "outputId": "d2163c22-5d57-4356-8148-8b1fe71902f7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El mundo es un lugar bonito para la vida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"ولی دختره عجب جنده با تجربه ای بود\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "translated = model.generate(**inputs, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
        "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "print(translated_text)  # Output: The world is a beautiful place to live."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dToYlett3gR_",
        "outputId": "35196a4e-74fc-47f7-b35d-317a7850139a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But the girl was great with experience.\n"
          ]
        }
      ]
    }
  ]
}